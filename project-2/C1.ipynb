{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import cv2 \n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "H5 = '/media/f4h1m/Dell External/CSE3200/Binary_classification/project-2/preprocessed_dataset/H5'\n",
    "H6 = '/media/f4h1m/Dell External/CSE3200/Binary_classification/project-2/preprocessed_dataset/H6'\n",
    "\n",
    "\n",
    "files_H5 = glob.glob(H5+ '/*.jpg')\n",
    "files_H6 = glob.glob(H6+ '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_labels = []\n",
    "\n",
    "\n",
    "for file in files_H5:\n",
    "    image = cv2.imread(file)\n",
    "    X_data.append(image)\n",
    "    y_labels.append(0)\n",
    "\n",
    "for file in files_H6:\n",
    "    image = cv2.imread(file)\n",
    "    X_data.append(image)\n",
    "    y_labels.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is ready\n"
     ]
    }
   ],
   "source": [
    "X_sets = np.array(X_data)\n",
    "m = X_sets.shape[0] #no of samples\n",
    "features_array = X_sets.reshape(X_sets.shape[0], -1).T # The rows represent the features, column represent the amount of samples\n",
    "\n",
    "y_labels = np.array(y_labels) #making it into a NumPy Array\n",
    "y =  y_labels.reshape(1,-1) # Remember that your output must be size (1,m)\n",
    "x  = features_array/255.0 #Normalise\n",
    "\n",
    "  \n",
    "# Randomly shuffling the datasets (Just in case it was set up in an orderly fashioned):\n",
    "# which in our case it is set up into two organised datasets so shuffling is a MUST\n",
    " \n",
    "permutation = list(np.random.permutation(m))\n",
    "shuffled_X = x[:, permutation]\n",
    "shuffled_Y = y[:, permutation] \n",
    "\n",
    "# Now split X and Y to training and test sets:\n",
    "\n",
    "# ~Percent % for training, ~Percent % for testing . (I am thinking it is too small to include dev sets)\n",
    "\n",
    "percent = 0.85  # Tune this to how much percent of training and test samples do you want.\n",
    "\n",
    "train_x =  shuffled_X[:,0:int(percent*m)]\n",
    "train_y =  shuffled_Y[:,0:int(percent*m)]\n",
    "\n",
    "test_x  = shuffled_X[:,int(percent*m):]\n",
    "test_y  = shuffled_Y[:,int(percent*m):]\n",
    "\n",
    "print('Dataset is ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape:  (96123, 1700)\n",
      "Test set shape:  (96123, 300)\n",
      "Training set labels shape:  (1, 1700)\n",
      "Test set labels shape:  (1, 300)\n"
     ]
    }
   ],
   "source": [
    "print('Training set shape: ', train_x.shape)\n",
    "print('Test set shape: ', test_x.shape)\n",
    "\n",
    "print('Training set labels shape: ', train_y.shape)\n",
    "print('Test set labels shape: ', test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise_parameters(layer_dims): # initialising forward propagation values\n",
    "    # Takes in the dimensions required for your neutral network (Layer Dimension)\n",
    "    # layers_dims = ( size of features (n_x),  size of hidden layer 1 (n_h1),...(size of other n_h)...., size of output (n_y))    \n",
    "    parameters = {} # Dictionary Type, easy access for variable name using key\n",
    "    L = len(layer_dims) # Number of layers wanted from neural network\n",
    "\n",
    "    for i in range(1,L): #Note: Range does not take upper bound number (which is what we want as input layer is not part of the hidden layer)\n",
    "        # Number of hidden layers = Number of weight and bias matrix needed\n",
    "               \n",
    "        parameters[\"W\" + str(i)] =  np.random.randn(layers_dims[i], layers_dims[i-1]) * (np.sqrt(2 / layers_dims[i-1] ))   # Weight Matrix \n",
    "        parameters[\"B\" + str(i)] =  np.zeros((layers_dims[i], 1))  # Bias Matrix (size: 1 column)\n",
    "   \n",
    "\n",
    "    return  parameters   # Returning parameters needed for forward propagation\n",
    "\n",
    "def initialise_past(parameters):\n",
    "    L = len(parameters) // 2 # Number of hidden layers wanted from neural network\n",
    "    past = {} #initialising dictionary\n",
    "    \n",
    "    for i in range(1,L+1):   \n",
    "        past[\"dW\" + str(i)] = parameters[\"W\" + str(i)] * 0.0 #same dimensions\n",
    "        past[\"dB\" + str(i)] = parameters[\"B\" + str(i)] * 0.0 #same dimensions\n",
    "\n",
    "    return past\n",
    "\n",
    "# Forward Propagation: (For now just do sigmoid for all)..........................\n",
    "    \n",
    "def sigmoid(x):  # Sigmoid Function\n",
    "    return  1 / (1 + np.exp(-x))\n",
    "\n",
    "# Activation Function\n",
    "def forward_activation(A_prev, W , b , activation):    \n",
    "    Z = np.dot(W,A_prev) + b  # Z: Value to put into function (sigmoid/ReLu) to get next activation unit\n",
    "    linear_cache = (A_prev,W,b) # Cache for backward propagation\n",
    "    # A: Activation Unit, W: Weight, b: bias\n",
    "       \n",
    "    if activation == \"sigmoid\": \n",
    "       A = sigmoid(Z) # next activation unit\n",
    "       activation_cache  = Z\n",
    "       \n",
    "    elif activation == \"relu\":\n",
    "        A = np.maximum(0,Z) # Activation through relu\n",
    "        activation_cache = Z\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A_prev.shape[1]))    \n",
    "    cache = (linear_cache, activation_cache)    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    \n",
    "    return A,cache\n",
    "\n",
    "\n",
    "# Forward Propagation\n",
    "def forward_propagate(X, parameters):    \n",
    "    caches = [] #Initialise empty cache (to append later on)\n",
    "    A = X # initial Activation unit is the input features\n",
    "    L = len(parameters) // 2 # Getting the length of hidden layer (Note: it is floor-ed cause indexes cannot take in float)\n",
    "    \n",
    "    for i in range(1,L): #remember the last weight is not included\n",
    "        A_prev  =  A #Current Activation Unit value that was calculated (Starting with inputs)\n",
    "        A,cache =  forward_activation(A_prev, parameters[\"W\"+str(i)] , parameters[\"B\"+str(i)] , \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    #For last activation: use sigmoid\n",
    "    \n",
    "    A_Last,cache =  forward_activation(A, parameters[\"W\"+str(L)] , parameters[\"B\"+str(L)] , \"sigmoid\") #calculating last activation unit\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return A_Last, caches\n",
    "    \n",
    "\n",
    "#Computing Cost\n",
    "def compute_regularised_cost(A_Last, Y,caches,lambd): # A_Last: Last activation unit (prediction) , Y: Data Output    \n",
    "     m  = Y.shape[1]  # Number of training samples ( Make sure output is size(1,Samples) )\n",
    "     L = len(caches)  # Length of hidden layers\n",
    "     total = 0 # will be broadcasted by weights\n",
    "     \n",
    "     for i in range(L):\n",
    "         \n",
    "        linear_cache, _ = caches[i]# from forward propagation\n",
    "        _ , W, _ = linear_cache\n",
    "        \n",
    "        summing = np.sum(W**2)\n",
    "        total  = total + summing\n",
    "     \n",
    "     cost = -(1/m) * ( np.dot(Y, np.log(A_Last).T)  +  np.dot( (1-Y), np.log(1-A_Last).T) ) # Using logarithmic cost function \n",
    "     \n",
    "     cost = np.squeeze(cost) # ensure cost array of size (1,1) to become just a singular number \n",
    "     # Squeeze is important as array multiplication in python always gives back an array\n",
    "    \n",
    "     reg_cost = (lambd/(2*m)) * total\n",
    "     regularised_cost = cost + reg_cost\n",
    "     \n",
    "     return regularised_cost \n",
    " \n",
    "\n",
    "   \n",
    "# Backward Propagation:     \n",
    "def backward_linear(dZ , cache ,lambd):    \n",
    "    A_prev, W, b = cache # From forward propogation \n",
    "    m = A_prev.shape[1] # Column of input features/activation units =  number of samples \n",
    "    \n",
    "    # Backprop Gradient formula\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T) + ((lambd/m) * W)\n",
    "    db = 1./m *  np.sum(dZ, axis = 1, keepdims =True) \n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "        \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "\n",
    "    return dA_prev, dW, db\n",
    "\n",
    "# Backward Activation\n",
    "def backward_activation(dA , cache , activation , lambd):\n",
    "    linear_cache, activation_cache = cache \n",
    "      \n",
    "    if activation == \"relu\":\n",
    "        Z = activation_cache\n",
    "        dZ = np.array(dA, copy=True) # check what does copy do in numpy array. ( Conversion to correct object)       \n",
    "        #dA is the derivative of dZ when above 0, think of y = x, dA/dZ  = 1\n",
    "        dZ[Z <= 0] = 0   #Logical index, when Z <= 0 , dZ will be = 0        \n",
    "        dA_prev, dW, db = backward_linear(dZ, linear_cache,lambd) # getting the gradient for linear calculations\n",
    "                \n",
    "    elif activation == \"sigmoid\":\n",
    "        Z = activation_cache \n",
    "        dZ =  dA  * sigmoid(Z)  * ( 1-sigmoid(Z) )  # Derivative for Sigmoid activation function (dZ)\n",
    "        dA_prev, dW, db = backward_linear(dZ, linear_cache,lambd) # getting the gradient for linear calculations\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "    \n",
    " \n",
    "# Back Propagation\n",
    "def backward_propagate(A_Last,Y,caches,lambd):    \n",
    "    gradients = {}\n",
    "    L = len(caches) # Number of hidden layer\n",
    "    Y = Y.reshape(A_Last.shape)  #Make sure outputs follows the same shape as the last activation unit\n",
    "    \n",
    "    # Backward propogate the output first (initialising) :\n",
    "    dA_Last = -(np.divide(Y, A_Last) - np.divide(1 - Y, 1 - A_Last)) # Derivative derived from Cost Function \n",
    "    current_cache = caches[L-1] # the last variable in the cache \n",
    "    gradients[\"dA\"+str(L-1)] , gradients[\"dW\" + str(L)], gradients[\"dB\" + str(L)] = backward_activation(dA_Last,current_cache,'sigmoid',lambd)\n",
    "    \n",
    "    for i in reversed(range(L-1)): #Going from the back of the range (from second last to 0), remember that the last one is already done (a step above)        \n",
    "        current_cache = caches[i]\n",
    "        dA_prev_temp, dW_temp, db_temp =  backward_activation(gradients[\"dA\" + str(i+1)],current_cache,'relu',lambd)\n",
    "        gradients[\"dA\" + str(i)] = dA_prev_temp\n",
    "        gradients[\"dW\" + str(i + 1)] = dW_temp\n",
    "        gradients[\"dB\" + str(i + 1)] = db_temp\n",
    "   \n",
    "    return gradients\n",
    "        \n",
    "# Gradient Descent\n",
    "def gradient_descent_momentum(parameters , gradients, learning_rate , beta , past):\n",
    "    L = len(parameters) // 2   #number of hidden layers\n",
    "    \n",
    "    for i in range(L):\n",
    "        # Idea for momentum is to have gradient descending with less oscillations.\n",
    "        # By storing using moving averages, the gradient value will react with some lag.\n",
    "       \n",
    "        past[\"dW\" + str(i+1)] = beta*past[\"dW\" + str(i+1)] + ((1-beta) * gradients[\"dW\"+str(i+1)])\n",
    "        past[\"dB\" + str(i+1)]=  beta*past[\"dB\" + str(i+1)] + ((1-beta) * gradients[\"dB\"+str(i+1)])     \n",
    "         \n",
    "        parameters[\"W\" + str(i+1)] =  parameters[\"W\" + str(i+1)]  -  learning_rate * past[\"dW\" + str(i+1)]\n",
    "        parameters[\"B\" + str(i+1)] =  parameters[\"B\" + str(i+1)]  -  learning_rate * past[\"dB\" + str(i+1)]\n",
    "         \n",
    "    return parameters\n",
    "\n",
    "\n",
    "# Separating data into batches for mini-batch gradient descent\n",
    "def batching(X, Y, mini_batch_size):    \n",
    "    m = X.shape[1]     # number of training examples\n",
    "    mini_batches = []  # Initialisation(List is used, need to append)     \n",
    "        \n",
    "   #Randomly shuffling the datasets (Just in case it was set up in an orderly fashioned)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation] #.reshape((1,m))\n",
    "\n",
    "   \n",
    "    num_of_minibatches = int(m/mini_batch_size) # number of mini batches for the whole training samples (floored by casting)    \n",
    "    \n",
    "    for i in range(num_of_minibatches):\n",
    "        \n",
    "        mini_batch_X = shuffled_X[:, i*mini_batch_size : (i+1)*mini_batch_size ]\n",
    "        mini_batch_Y = shuffled_Y[:, i*mini_batch_size : (i+1)*mini_batch_size ]\n",
    "    \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # For the last batch only if there is an extra batch that was left out after sectioning:\n",
    "    \n",
    "    if m % mini_batch_size != 0: # if there is an extra last batch:        \n",
    "        \n",
    "        mini_batch_X = X[:, num_of_minibatches*mini_batch_size :  ] # the last batch till the end \n",
    "        mini_batch_Y = Y[:, num_of_minibatches*mini_batch_size :  ]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "# The Neural Network model:\n",
    "\n",
    "def NN_model(X,Y, layers_dims, learning_rate ,beta, lambd, epochs , minibatch_size):\n",
    "    costs = [] # keeping track of cost (plot later or print to confirm that error is decreasing)\n",
    "    \n",
    "    parameters = initialise_parameters(layers_dims) # get all the parameters necessary according to the wanted NN layers.\n",
    "    past = initialise_past(parameters)  # past values of gradient\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs): # Epochs = number of times it goes through the whole training samples  \n",
    "      \n",
    "        # Per Epoch (one whole training sample), it iterate through a few mini-batches for the whole training samples:\n",
    "        \n",
    "        mini_batches = batching( X, Y, minibatch_size)  # Separate training samples to mini-batches\n",
    "        # batching returns all of the mini-batches of the entire training sample\n",
    "        # Mini-batches are in a list\n",
    "    \n",
    "        for batch in mini_batches:        \n",
    "            ( batch_x,  batch_y)  =  batch  # Mini-batches of the samples:\n",
    "            A_Last, caches =  forward_propagate(batch_x, parameters) #Forward Propagation\n",
    "            cost = compute_regularised_cost(A_Last, batch_y , caches,lambd ) # Computation of Cost (log function)               \n",
    "            gradients = backward_propagate(A_Last, batch_y , caches , lambd) #Backward Propagation\n",
    "            parameters = gradient_descent_momentum(parameters , gradients, learning_rate , beta , past)  #Gradient Descent\n",
    "        \n",
    "        if  epoch % 50 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" %(epoch, cost))\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('Epoch (per fifty)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "        \n",
    "    return parameters # Weight and Bias Matrix that best fits the training data.\n",
    "\n",
    "# Prediction based off the weight and bias that has been calculated:\n",
    "def predict(X, parameters): # Predicting based off NN predictions    \n",
    "     m =  X.shape[1]  # size of sample \n",
    "     prediction = np.zeros((1,m)) # because the output matrix is size (1,number of samples)\n",
    "     \n",
    "     # Forward Propagate the Updated Parameters     \n",
    "     A_Last , caches = forward_propagate(X, parameters)  #A_Last is the prediction \n",
    "     \n",
    "     for i in range(0,m):\n",
    "         if A_Last[0,i] > 0.5: # using sigmoid, if probability above 0.5 == positive\n",
    "             prediction[0,i] = 1\n",
    "         else:\n",
    "             prediction[0,i] = 0\n",
    "     \n",
    "     return prediction\n",
    " \n",
    "     \n",
    "# USER GUIDE: \n",
    "\n",
    "#  How to use the neutral network algorithm:\n",
    "     \n",
    "#  Step 1. Set up input data (X) to be size - (number of features, number of samples)\n",
    "#  Step 2. Set up output data (Y) to be size - (1,number of samples) as NN returns output of size (1 , number of samples)\n",
    "#  Step 3. Set up the size and number of neutral network layers that you want to test with. \n",
    "#          layers_dims = ( size of features (n_x),  size of hidden layer 1 (n_h1),...(size of other n_h)...., size of output (n_y))\n",
    "#  Step 4. Use the NN function. NN_model(X,Y, layers_dims, learning_rate , iterations )\n",
    "#         - Cost function will be plotted. Use it to make sure cost is reaching steady-state.\n",
    "#         - Tune Learning rate accordingly\n",
    "#  Step 5. Use the predict function. Accuracy of prediction will be computed.\n",
    "#        - predict(train_x, train_y, parameters). Updated parameters comes from NN_model\n",
    "#        - Use on Training Data first. ( Ensure it is of high accuracy to begin with)\n",
    "#        - Proceed with Testing Data. \n",
    "#        - Accuracy of testing data is usually pretty low with this NN. We can definitely improve it!\n",
    "#        - Stay tune for updates!\n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0: 3.483659\n",
      "Cost after epoch 50: 0.747155\n",
      "Cost after epoch 100: 0.534880\n",
      "Cost after epoch 150: 0.506190\n",
      "Cost after epoch 200: 0.510215\n",
      "Cost after epoch 250: 0.483148\n",
      "Cost after epoch 300: 0.586926\n",
      "Cost after epoch 350: 0.504539\n",
      "Cost after epoch 400: 0.492737\n",
      "Cost after epoch 450: 0.495625\n",
      "Cost after epoch 500: 0.489663\n",
      "Cost after epoch 550: 0.487798\n",
      "Cost after epoch 600: 0.486810\n",
      "Cost after epoch 650: 0.492378\n",
      "Cost after epoch 700: 0.513962\n",
      "Cost after epoch 750: 0.494962\n",
      "Cost after epoch 800: 0.488691\n",
      "Cost after epoch 850: 0.499123\n",
      "Cost after epoch 900: 0.675282\n",
      "Cost after epoch 950: 0.494774\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time:3973.4182937145233 seconds\n",
      "Accuracy of training sets: 0.7976470588235295\n",
      "Accuracy of testing sets: 0.7566666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_size = train_x.shape[0] # size of inputs (features)\n",
    "layers_dims = (features_size,16, 1) # Layer model that you want. \n",
    "start = time.time() # Timing how long it takes to train\n",
    "\n",
    "parameters =  NN_model(\n",
    "    train_x,train_y, \n",
    "    layers_dims, \n",
    "    learning_rate = 0.0090, \n",
    "    beta = 0.90, \n",
    "    lambd = 6.3 ,  \n",
    "    epochs = 1000, \n",
    "    minibatch_size = 64\n",
    ") \n",
    "\n",
    "\n",
    "end = time.time()\n",
    "process_time =  end-start\n",
    "print('Process Time:' + str(process_time) + \" \" + 'seconds')\n",
    "\n",
    "\n",
    "             \n",
    "# Check Accuracy for training sets:  \n",
    "predict_train = predict(train_x,parameters) # Get predictions for training sets \n",
    "\n",
    "sample_train = predict_train.shape[1]\n",
    "accuracy_train = np.sum((predict_train == train_y)/sample_train)  \n",
    "print(\"Accuracy of training sets: \"  + str(accuracy_train) )\n",
    "\n",
    "\n",
    "\n",
    "# Check Accuracy for testing sets:   \n",
    "predict_test = predict(test_x,parameters) # Get predictions for testing sets \n",
    "\n",
    "sample_test = predict_test.shape[1]\n",
    "accuracy_test = np.sum((predict_test == test_y)/sample_test)  \n",
    "print(\"Accuracy of testing sets: \"  + str(accuracy_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model as .h5 file\n",
    "import h5py\n",
    "import os\n",
    "os.chdir('/media/f4h1m/Dell External/CSE3200/Binary_classification/project-2')\n",
    "\n",
    "f = h5py.File('model.h5', 'w')\n",
    "for key in parameters:\n",
    "    f.create_dataset(key, data=parameters[key])\n",
    "f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exlude comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_h5(model, filepath):\n",
    "    with h5py.File(filepath, 'w') as file:\n",
    "        # Save the weights and biases or any other model parameters as needed\n",
    "        file.create_dataset('weights_input_hidden', data=model.weights_input_hidden)\n",
    "        file.create_dataset('bias_hidden', data=model.bias_hidden)\n",
    "        file.create_dataset('weights_hidden_output', data=model.weights_hidden_output)\n",
    "        file.create_dataset('bias_output', data=model.bias_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_h5()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
