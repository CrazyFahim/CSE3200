{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import cv2 \n",
    "import time\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "H5 = '/media/f4h1m/Dell External/CSE3200/Binary_classification/project-2/preprocessed_dataset/H5'\n",
    "H6 = '/media/f4h1m/Dell External/CSE3200/Binary_classification/project-2/preprocessed_dataset/H6'\n",
    "\n",
    "\n",
    "files_H5 = glob.glob(H5+ '/*.jpg')\n",
    "files_H6 = glob.glob(H6+ '/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = []\n",
    "y_labels = []\n",
    "\n",
    "\n",
    "for file in files_H5:\n",
    "    image = cv2.imread(file)\n",
    "    X_data.append(image)\n",
    "    y_labels.append(0)\n",
    "\n",
    "for file in files_H6:\n",
    "    image = cv2.imread(file)\n",
    "    X_data.append(image)\n",
    "    y_labels.append(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is ready\n"
     ]
    }
   ],
   "source": [
    "X_sets = np.array(X_data)\n",
    "m = X_sets.shape[0] #no of samples\n",
    "features_array = X_sets.reshape(X_sets.shape[0], -1).T # The rows represent the features, column represent the amount of samples\n",
    "\n",
    "y_labels = np.array(y_labels) #making it into a NumPy Array\n",
    "y =  y_labels.reshape(1,-1) # Remember that your output must be size (1,m)\n",
    "x  = features_array/255.0 #Normalise\n",
    "\n",
    "  \n",
    "# Randomly shuffling the datasets (Just in case it was set up in an orderly fashioned):\n",
    "# which in our case it is set up into two organised datasets so shuffling is a MUST\n",
    " \n",
    "permutation = list(np.random.permutation(m))\n",
    "shuffled_X = x[:, permutation]\n",
    "shuffled_Y = y[:, permutation] \n",
    "\n",
    "# Now split X and Y to training and test sets:\n",
    "\n",
    "# ~Percent % for training, ~Percent % for testing . (I am thinking it is too small to include dev sets)\n",
    "\n",
    "percent = 0.85  # Tune this to how much percent of training and test samples do you want.\n",
    "\n",
    "train_x =  shuffled_X[:,0:int(percent*m)]\n",
    "train_y =  shuffled_Y[:,0:int(percent*m)]\n",
    "\n",
    "test_x  = shuffled_X[:,int(percent*m):]\n",
    "test_y  = shuffled_Y[:,int(percent*m):]\n",
    "\n",
    "print('Dataset is ready')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is ready\n",
      "Cost after epoch 0: 3.464953\n",
      "Cost after epoch 50: 0.675175\n",
      "Cost after epoch 100: 0.511598\n",
      "Cost after epoch 150: 0.415568\n",
      "Cost after epoch 200: 0.416483\n",
      "Cost after epoch 250: 0.445599\n",
      "Cost after epoch 300: 0.419822\n",
      "Cost after epoch 350: 0.414809\n",
      "Cost after epoch 400: 0.461533\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Time:1469.4409112930298 seconds\n",
      "Accuracy of training sets: 0.7882352941176471\n",
      "Accuracy of testing sets: 0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "def initialise_parameters(layer_dims): # initialising forward propagation values\n",
    "    # Takes in the dimensions required for your neutral network (Layer Dimension)\n",
    "    # layers_dims = ( size of features (n_x),  size of hidden layer 1 (n_h1),...(size of other n_h)...., size of output (n_y))\n",
    "    \n",
    "    parameters = {} # Dictionary Type, easy access for variable name using key\n",
    "    L = len(layer_dims) # Number of layers wanted from neural network\n",
    "\n",
    "    for i in range(1,L): #Note: Range does not take upper bound number (which is what we want as input layer is not part of the hidden layer)\n",
    "        # Number of hidden layers = Number of weight and bias matrix needed\n",
    "       \n",
    "        \n",
    "        parameters[\"W\" + str(i)] =  np.random.randn(layers_dims[i], layers_dims[i-1]) * (np.sqrt(2 / layers_dims[i-1] ))   # Weight Matrix \n",
    "        parameters[\"B\" + str(i)] =  np.zeros((layers_dims[i], 1))  # Bias Matrix (size: 1 column)\n",
    "   \n",
    "\n",
    "    return  parameters   # Returning parameters needed for forward propagation\n",
    "\n",
    "def initialise_past(parameters):\n",
    "    \n",
    "    L = len(parameters) // 2 # Number of hidden layers wanted from neural network\n",
    "    past = {} #initialising dictionary\n",
    "    \n",
    "    for i in range(1,L+1):\n",
    "   \n",
    "     past[\"dW\" + str(i)] = parameters[\"W\" + str(i)] * 0.0 #same dimensions\n",
    "     past[\"dB\" + str(i)] = parameters[\"B\" + str(i)] * 0.0 #same dimensions\n",
    "\n",
    "    return past\n",
    "\n",
    "# Forward Propagation: (For now just do sigmoid for all)..........................\n",
    "    \n",
    "def sigmoid(x):  # Sigmoid Function\n",
    "  return  1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def forward_activation(A_prev, W , b , activation):\n",
    "    \n",
    "    Z = np.dot(W,A_prev) + b  # Z: Value to put into function (sigmoid/ReLu) to get next activation unit\n",
    "    linear_cache = (A_prev,W,b) # Cache for backward propagation\n",
    "    # A: Activation Unit, W: Weight, b: bias\n",
    "       \n",
    "    if activation == \"sigmoid\": \n",
    "       A = sigmoid(Z) # next activation unit\n",
    "       activation_cache  = Z\n",
    "       \n",
    "    elif activation == \"relu\":\n",
    "        A = np.maximum(0,Z) # Activation through relu\n",
    "        activation_cache = Z\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    \n",
    "    cache = (linear_cache, activation_cache)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    \n",
    "    return A,cache\n",
    "\n",
    "\n",
    "    \n",
    "def forward_propagate(X, parameters):\n",
    "    \n",
    "    caches = [] #Initialise empty cache (to append later on)\n",
    "    A = X # initial Activation unit is the input features\n",
    "    L = len(parameters) // 2 # Getting the length of hidden layer (Note: it is floor-ed cause indexes cannot take in float)\n",
    "    \n",
    "    for i in range(1,L): #remember the last weight is not included\n",
    "        A_prev  =  A #Current Activation Unit value that was calculated (Starting with inputs)\n",
    "        A,cache =  forward_activation(A_prev, parameters[\"W\"+str(i)] , parameters[\"B\"+str(i)] , \"relu\")\n",
    "        caches.append(cache)\n",
    "    \n",
    "    #For last activation: use sigmoid\n",
    "    \n",
    "    A_Last,cache =  forward_activation(A, parameters[\"W\"+str(L)] , parameters[\"B\"+str(L)] , \"sigmoid\") #calculating last activation unit\n",
    "    caches.append(cache)\n",
    "    \n",
    "    \n",
    "    return A_Last, caches\n",
    "    \n",
    "#...............................................................................  \n",
    "    \n",
    "\n",
    "#Computing Cost\n",
    "def compute_regularised_cost(A_Last, Y,caches,lambd): # A_Last: Last activation unit (prediction) , Y: Data Output\n",
    "    \n",
    "     m  = Y.shape[1]  # Number of training samples ( Make sure output is size(1,Samples) )\n",
    "     L = len(caches)  # Length of hidden layers\n",
    "     total = 0 # will be broadcasted by weights\n",
    "     \n",
    "     for i in range(L):\n",
    "         \n",
    "        linear_cache, _ = caches[i]# from forward propagation\n",
    "        _ , W, _ = linear_cache\n",
    "        \n",
    "        summing = np.sum(W**2)\n",
    "        total  = total + summing\n",
    "     \n",
    "     cost = -(1/m) * ( np.dot(Y, np.log(A_Last).T)  +  np.dot( (1-Y), np.log(1-A_Last).T) ) # Using logarithmic cost function \n",
    "     \n",
    "     cost = np.squeeze(cost) # ensure cost array of size (1,1) to become just a singular number \n",
    "     # Squeeze is important as array multiplication in python always gives back an array\n",
    "    \n",
    "     reg_cost = (lambd/(2*m)) * total\n",
    "     regularised_cost = cost + reg_cost\n",
    "     \n",
    "     return regularised_cost \n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "   \n",
    "# Backward Propagation:........................................................\n",
    "     \n",
    "def backward_linear(dZ , cache ,lambd):\n",
    "    \n",
    "    A_prev, W, b = cache # From forward propogation \n",
    "    m = A_prev.shape[1] # Column of input features/activation units =  number of samples \n",
    "    \n",
    "    # Backprop Gradient formula\n",
    "    dW = 1./m * np.dot(dZ,A_prev.T) + ((lambd/m) * W)\n",
    "    db = 1./m *  np.sum(dZ, axis = 1, keepdims =True) \n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "        \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "\n",
    "    return dA_prev, dW, db\n",
    "    \n",
    "def backward_activation(dA , cache , activation , lambd):\n",
    "    \n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "      \n",
    "    if activation == \"relu\":\n",
    "        \n",
    "        Z = activation_cache\n",
    "        \n",
    "        dZ = np.array(dA, copy=True) # check what does copy do in numpy array. ( Conversion to correct object)       \n",
    "        #dA is the derivative of dZ when above 0, think of y = x, dA/dZ  = 1\n",
    "        dZ[Z <= 0] = 0   #Logical index, when Z <= 0 , dZ will be = 0\n",
    "     \n",
    "        \n",
    "        dA_prev, dW, db = backward_linear(dZ, linear_cache,lambd) # getting the gradient for linear calculations\n",
    "        \n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        \n",
    "        Z = activation_cache \n",
    "        \n",
    "        dZ =  dA  * sigmoid(Z)  * ( 1-sigmoid(Z) )  # Derivative for Sigmoid activation function (dZ)\n",
    "        dA_prev, dW, db = backward_linear(dZ, linear_cache,lambd) # getting the gradient for linear calculations\n",
    "\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "    \n",
    " \n",
    "def backward_propagate(A_Last,Y,caches,lambd):\n",
    "    \n",
    "    gradients = {}\n",
    "    L = len(caches) # Number of hidden layer\n",
    "    Y = Y.reshape(A_Last.shape)  #Make sure outputs follows the same shape as the last activation unit\n",
    "    \n",
    "    # Backward propogate the output first (initialising) :\n",
    "    \n",
    "    dA_Last = -(np.divide(Y, A_Last) - np.divide(1 - Y, 1 - A_Last)) # Derivative derived from Cost Function \n",
    "    current_cache = caches[L-1] # the last variable in the cache \n",
    "    gradients[\"dA\"+str(L-1)] , gradients[\"dW\" + str(L)], gradients[\"dB\" + str(L)] = backward_activation(dA_Last,current_cache,'sigmoid',lambd)\n",
    "    \n",
    "    for i in reversed(range(L-1)): #Going from the back of the range (from second last to 0), remember that the last one is already done (a step above)\n",
    "        \n",
    "        current_cache = caches[i]\n",
    "        dA_prev_temp, dW_temp, db_temp =  backward_activation(gradients[\"dA\" + str(i+1)],current_cache,'relu',lambd)\n",
    "        gradients[\"dA\" + str(i)] = dA_prev_temp\n",
    "        gradients[\"dW\" + str(i + 1)] = dW_temp\n",
    "        gradients[\"dB\" + str(i + 1)] = db_temp\n",
    "   \n",
    "    return gradients\n",
    "        \n",
    "# Gradient Descent...........................................................\n",
    "\n",
    "def gradient_descent_momentum(parameters , gradients, learning_rate , beta , past):\n",
    "    \n",
    "    L = len(parameters) // 2   #number of hidden layers\n",
    "    \n",
    "    for i in range(L):\n",
    "        \n",
    "        # Idea for momentum is to have gradient descending with less oscillations.\n",
    "        # By storing using moving averages, the gradient value will react with some lag.\n",
    "       \n",
    "         past[\"dW\" + str(i+1)] = beta*past[\"dW\" + str(i+1)] + ((1-beta) * gradients[\"dW\"+str(i+1)])\n",
    "         past[\"dB\" + str(i+1)]=  beta*past[\"dB\" + str(i+1)] + ((1-beta) * gradients[\"dB\"+str(i+1)])\n",
    "         \n",
    "         \n",
    "         parameters[\"W\" + str(i+1)] =  parameters[\"W\" + str(i+1)]  -  learning_rate * past[\"dW\" + str(i+1)]\n",
    "         parameters[\"B\" + str(i+1)] =  parameters[\"B\" + str(i+1)]  -  learning_rate * past[\"dB\" + str(i+1)]\n",
    "         \n",
    "    return parameters\n",
    "\n",
    "# Separating data into batches for mini-batch gradient descent................\n",
    "\n",
    "def batching(X, Y, mini_batch_size):\n",
    " \n",
    "    \n",
    "    m = X.shape[1]     # number of training examples\n",
    "    mini_batches = []  # Initialisation(List is used, need to append)     \n",
    "        \n",
    "   #Randomly shuffling the datasets (Just in case it was set up in an orderly fashioned)\n",
    "    permutation = list(np.random.permutation(m))\n",
    "    shuffled_X = X[:, permutation]\n",
    "    shuffled_Y = Y[:, permutation] #.reshape((1,m))\n",
    "\n",
    "   \n",
    "    num_of_minibatches = int(m/mini_batch_size) # number of mini batches for the whole training samples (floored by casting)\n",
    "    \n",
    "    \n",
    "    for i in range(num_of_minibatches):\n",
    "        \n",
    "        mini_batch_X = shuffled_X[:, i*mini_batch_size : (i+1)*mini_batch_size ]\n",
    "        mini_batch_Y = shuffled_Y[:, i*mini_batch_size : (i+1)*mini_batch_size ]\n",
    "    \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    # For the last batch only if there is an extra batch that was left out after sectioning:\n",
    "    \n",
    "    if m % mini_batch_size != 0: # if there is an extra last batch:\n",
    "        \n",
    "        \n",
    "        mini_batch_X = X[:, num_of_minibatches*mini_batch_size :  ] # the last batch till the end \n",
    "        mini_batch_Y = Y[:, num_of_minibatches*mini_batch_size :  ]\n",
    "        \n",
    "        mini_batch = (mini_batch_X, mini_batch_Y)\n",
    "        mini_batches.append(mini_batch)\n",
    "    \n",
    "    return mini_batches\n",
    "\n",
    "\n",
    "# The Neural Network model:..........................................\n",
    "\n",
    "def NN_model(X,Y, layers_dims, learning_rate ,beta, lambd, epochs , minibatch_size):\n",
    "    \n",
    "    costs = [] # keeping track of cost (plot later or print to confirm that error is decreasing)\n",
    "    \n",
    "    parameters = initialise_parameters(layers_dims) # get all the parameters necessary according to the wanted NN layers.\n",
    "    past = initialise_past(parameters)  # past values of gradient\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs): # Epochs = number of times it goes through the whole training samples  \n",
    "      \n",
    "        # Per Epoch (one whole training sample), it iterate through a few mini-batches for the whole training samples:\n",
    "        \n",
    "        mini_batches = batching( X, Y, minibatch_size)  # Separate training samples to mini-batches\n",
    "        # batching returns all of the mini-batches of the entire training sample\n",
    "        # Mini-batches are in a list\n",
    "    \n",
    "        for batch in mini_batches:\n",
    "        \n",
    "            ( batch_x,  batch_y)  =  batch  # Mini-batches of the samples:\n",
    "        \n",
    "            A_Last, caches =  forward_propagate(batch_x, parameters) #Forward Propagation\n",
    "\n",
    "            cost = compute_regularised_cost(A_Last, batch_y , caches,lambd ) # Computation of Cost (log function)\n",
    "               \n",
    "            gradients = backward_propagate(A_Last, batch_y , caches , lambd) #Backward Propagation\n",
    "\n",
    "            parameters = gradient_descent_momentum(parameters , gradients, learning_rate , beta , past)  #Gradient Descent\n",
    "        \n",
    "        if  epoch % 50 == 0:\n",
    "            print (\"Cost after epoch %i: %f\" %(epoch, cost))\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('Epoch (per fifty)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "        \n",
    "    return parameters # Weight and Bias Matrix that best fits the training data.\n",
    "\n",
    "# Prediction based off the weight and bias that has been calculated:....................\n",
    "def predict(X, parameters): # Predicting based off NN predictions\n",
    "    \n",
    "     m =  X.shape[1]  # size of sample \n",
    "     prediction = np.zeros((1,m)) # because the output matrix is size (1,number of samples)\n",
    "     \n",
    "     # Forward Propagate the Updated Parameters\n",
    "     \n",
    "     A_Last , caches = forward_propagate(X, parameters)  #A_Last is the prediction \n",
    "     \n",
    "     for i in range(0,m):\n",
    "         if A_Last[0,i] > 0.5: # using sigmoid, if probability above 0.5 == positive\n",
    "             prediction[0,i] = 1\n",
    "         else:\n",
    "             prediction[0,i] = 0\n",
    "     \n",
    "     return prediction\n",
    " \n",
    "     \n",
    "'''   ......................................\n",
    "\n",
    " How to use the neutral network algorithm:\n",
    "     \n",
    " Step 1. Set up input data (X) to be size - (number of features, number of samples)\n",
    " Step 2. Set up output data (Y) to be size - (1,number of samples) as NN returns output of size (1 , number of samples)\n",
    " Step 3. Set up the size and number of neutral network layers that you want to test with. \n",
    "         layers_dims = ( size of features (n_x),  size of hidden layer 1 (n_h1),...(size of other n_h)...., size of output (n_y))\n",
    " Step 4. Use the NN function. NN_model(X,Y, layers_dims, learning_rate , iterations )\n",
    "        - Cost function will be plotted. Use it to make sure cost is reaching steady-state.\n",
    "        - Tune Learning rate accordingly\n",
    " Step 5. Use the predict function. Accuracy of prediction will be computed.\n",
    "       - predict(train_x, train_y, parameters). Updated parameters comes from NN_model\n",
    "       - Use on Training Data first. ( Ensure it is of high accuracy to begin with)\n",
    "       - Proceed with Testing Data. \n",
    "       - Accuracy of testing data is usually pretty low with this NN. We can definitely improve it!\n",
    "       - Stay tune for updates!\n",
    "    \n",
    "'''  \n",
    "\n",
    "\n",
    "# Conversion of image to data: COMPLETE................................................................\n",
    " \n",
    "# MAIN:........................................................................\n",
    "\n",
    "features_size = train_x.shape[0] # size of inputs (features)\n",
    "\n",
    "layers_dims = (features_size,16, 1) # Layer model that you want. \n",
    "\n",
    "start = time.time() # Timing how long it takes to train\n",
    "\n",
    "parameters =  NN_model(train_x,train_y, layers_dims, learning_rate = 0.0090, beta = 0.90, lambd = 6.3 ,  epochs = 450 , minibatch_size = 64 ) \n",
    "\n",
    "end = time.time()\n",
    "\n",
    "process_time =  end-start\n",
    "\n",
    "print('Process Time:' + str(process_time) + \" \" + 'seconds')\n",
    "\n",
    "\n",
    "             \n",
    "# Check Accuracy for training sets: .....\n",
    "  \n",
    "predict_train = predict(train_x,parameters) # Get predictions for training sets \n",
    "\n",
    "sample_train = predict_train.shape[1]\n",
    "accuracy_train = np.sum((predict_train == train_y)/sample_train)  \n",
    "print(\"Accuracy of training sets: \"  + str(accuracy_train) )\n",
    "\n",
    "# Check Accuracy for testing sets: ....\n",
    "  \n",
    "predict_test = predict(test_x,parameters) # Get predictions for testing sets \n",
    "\n",
    "sample_test = predict_test.shape[1]\n",
    "accuracy_test = np.sum((predict_test == test_y)/sample_test)  \n",
    "print(\"Accuracy of testing sets: \"  + str(accuracy_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
